<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3D Pose Estimation</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        body {
            padding-top: 20px;
            padding-bottom: 20px;
        }
        .container {
            max-width: 960px;
        }
        .tab-content {
            padding: 20px;
            border: 1px solid #dee2e6;
            border-top: 0;
            border-radius: 0 0 0.25rem 0.25rem;
        }
        #video-preview, #captured-image, #captured-video {
            width: 100%;
            max-height: 400px;
            border: 1px solid #ddd;
            margin-bottom: 10px;
        }
        .countdown {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            font-size: 100px;
            color: white;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.7);
            z-index: 10;
        }
        .preview-container {
            position: relative;
        }
        .recording-indicator {
            position: absolute;
            top: 10px;
            right: 10px;
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background-color: red;
            animation: blink 1s infinite;
        }
        @keyframes blink {
            0% { opacity: 1; }
            50% { opacity: 0; }
            100% { opacity: 1; }
        }
        .btn-group {
            margin-bottom: 15px;
        }
        .result-container {
            margin-top: 20px;
            padding: 15px;
            border: 1px solid #ddd;
            border-radius: 5px;
            background-color: #f9f9f9;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1 class="text-center mb-4">3D Pose Estimation</h1>
        
        <ul class="nav nav-tabs" id="myTab" role="tablist">
            <li class="nav-item" role="presentation">
                <button class="nav-link active" id="upload-tab" data-bs-toggle="tab" data-bs-target="#upload" type="button" role="tab" aria-controls="upload" aria-selected="true">Upload</button>
            </li>
            <li class="nav-item" role="presentation">
                <button class="nav-link" id="capture-tab" data-bs-toggle="tab" data-bs-target="#capture" type="button" role="tab" aria-controls="capture" aria-selected="false">Capture</button>
            </li>
        </ul>
        
        <div class="tab-content" id="myTabContent">
            <!-- Upload Tab -->
            <div class="tab-pane fade show active" id="upload" role="tabpanel" aria-labelledby="upload-tab">
                <div class="mb-3">
                    <label for="file-upload" class="form-label">Upload Image or Video</label>
                    <input class="form-control" type="file" id="file-upload" accept="image/*, video/*, .mov, .MOV">
                </div>
                <div id="upload-preview" class="mb-3 d-none">
                    <h5>Preview:</h5>
                    <img id="image-preview" class="d-none" alt="Image Preview" style="max-width: 100%;">
                    <video id="video-file-preview" class="d-none" controls style="max-width: 100%;"></video>
                </div>
                <button id="upload-btn" class="btn btn-primary" disabled>Estimate pose!</button>
            </div>
            
            <!-- Capture Tab -->
            <div class="tab-pane fade" id="capture" role="tabpanel" aria-labelledby="capture-tab">
                <div class="btn-group mb-3" role="group">
                    <input type="radio" class="btn-check" name="capture-type" id="image-option" autocomplete="off" checked>
                    <label class="btn btn-outline-primary" for="image-option">Image</label>
                    
                    <input type="radio" class="btn-check" name="capture-type" id="video-option" autocomplete="off">
                    <label class="btn btn-outline-primary" for="video-option">Video</label>
                </div>
                
                <div class="preview-container mb-3">
                    <video id="video-preview" autoplay muted></video>
                    <div id="countdown" class="countdown d-none"></div>
                    <div id="recording-indicator" class="recording-indicator d-none"></div>
                </div>
                
                <div id="capture-controls">
                    <button id="start-capture" class="btn btn-primary">Start Camera</button>
                    <button id="capture-btn" class="btn btn-success d-none">Capture</button>
                    <button id="stop-capture" class="btn btn-danger d-none">Stop</button>
                </div>
                
                <div id="capture-result" class="mt-3 d-none">
                    <h5>Captured:</h5>
                    <img id="captured-image" class="d-none" alt="Captured Image">
                    <video id="captured-video" class="d-none" controls></video>
                    <button id="save-capture" class="btn btn-primary mt-2">Save</button>
                    <button id="retake" class="btn btn-secondary mt-2">Retake</button>
                </div>
            </div>
        </div>
        
        <!-- Processing Section -->
        <div id="processing-section" class="mt-4 d-none">
            <h3>Processing</h3>
            <div class="mb-3">
                <p id="status-indicator">Status: Ready</p>
            </div>
            
            <div id="result-container" class="result-container mt-3 d-none">
                <h4>Analysis Results</h4>
                
                <!-- Image result container -->
                <div id="image-result-container" class="mt-3">
                    <!-- Original image -->
                    <div class="mb-3">
                        <h5>Original Image</h5>
                        <img id="original-image" class="img-fluid" style="max-width: 100%; width: 100%;">
                    </div>
                    
                    <!-- 3D Visualization -->
                    <div class="mb-3">
                        <h5>3D Visualization <small class="text-muted fw-normal" style="font-size:0.75rem;">드래그로 회전 · 스크롤로 줌</small></h5>
                        <div id="plot-div" style="width:100%; height:500px; background:#16213e; border-radius:8px; transition: height 0.2s ease;"></div>
                    </div>
                </div>
                
                <!-- Video result container -->
                <div id="video-result-container" class="mt-3 d-none">
                    <h5>Video Analysis</h5>
                    <!-- Original video -->
                    <div class="mb-3">
                        <p>Original Video:</p>
                        <video id="original-video" controls style="max-width: 100%; width: 100%;" class="mb-2"></video>
                        <div class="d-flex justify-content-between align-items-center">
                            <button id="play-pause-btn" class="btn btn-primary btn-sm">Play</button>
                            <input type="range" id="video-slider" class="form-range mx-2" min="0" max="100" value="0" style="flex-grow: 1;">
                            <span id="current-frame">0/0</span>
                        </div>
                    </div>
                    
                    <!-- Pose visualization -->
                    <div class="mb-3">
                        <p>Pose Visualization: <small class="text-muted" style="font-size:0.75rem;">드래그로 회전 · 스크롤로 줌</small></p>
                        <div id="frame-plot-div" style="width:100%; height:500px; background:#16213e; border-radius:8px; transition: height 0.2s ease;"></div>
                    </div>
                </div>
                
                <div class="mt-3">
                    <button id="download-csv" class="btn btn-success">Save Result as CSV</button>
                </div>
            </div>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
    <script>
        // ── Plotly 3D skeleton constants ──────────────────────────────────────
        const KEYPOINT_NAMES = [
            'TOP','NECK','RIGHT_SHOULDER','RIGHT_ELBOW','RIGHT_WRIST',
            'LEFT_SHOULDER','LEFT_ELBOW','LEFT_WRIST','RIGHT_HIP','RIGHT_KNEE',
            'RIGHT_ANKLE','LEFT_HIP','LEFT_KNEE','LEFT_ANKLE','NOSE',
            'RIGHT_EYE','RIGHT_EAR','LEFT_EYE','LEFT_EAR','SPINE',
            'RIGHT_FINGER','RIGHT_TOE','LEFT_FINGER','LEFT_TOE','STERNUM','SACRUM'
        ];
        const BONE_CONNECTIONS = [
            {from:0,  to:1,  color:'rgb(25,175,25)'},   // TOP-NECK
            {from:1,  to:2,  color:'rgb(25,25,175)'},   // NECK-R_SHOULDER
            {from:1,  to:5,  color:'rgb(255,25,25)'},   // NECK-L_SHOULDER
            {from:7,  to:6,  color:'rgb(255,25,25)'},   // L_WRIST-L_ELBOW
            {from:6,  to:5,  color:'rgb(255,25,25)'},   // L_ELBOW-L_SHOULDER
            {from:5,  to:2,  color:'rgb(25,175,25)'},   // L_SHOULDER-R_SHOULDER
            {from:2,  to:3,  color:'rgb(25,25,175)'},   // R_SHOULDER-R_ELBOW
            {from:3,  to:4,  color:'rgb(25,25,175)'},   // R_ELBOW-R_WRIST
            {from:19, to:24, color:'rgb(25,175,25)'},   // SPINE-STERNUM
            {from:11, to:8,  color:'rgb(25,175,25)'},   // L_HIP-R_HIP
            {from:19, to:25, color:'rgb(25,175,25)'},   // SPINE-SACRUM
            {from:11, to:12, color:'rgb(255,25,25)'},   // L_HIP-L_KNEE
            {from:12, to:13, color:'rgb(255,25,25)'},   // L_KNEE-L_ANKLE
            {from:8,  to:9,  color:'rgb(25,25,175)'},   // R_HIP-R_KNEE
            {from:9,  to:10, color:'rgb(25,25,175)'},   // R_KNEE-R_ANKLE
            {from:14, to:0,  color:'rgb(25,175,25)'},   // NOSE-TOP
            {from:14, to:1,  color:'rgb(25,175,25)'},   // NOSE-NECK
            {from:14, to:15, color:'rgb(25,25,175)'},   // NOSE-R_EYE
            {from:14, to:17, color:'rgb(255,25,25)'},   // NOSE-L_EYE
            {from:15, to:16, color:'rgb(25,25,175)'},   // R_EYE-R_EAR
            {from:17, to:18, color:'rgb(255,25,25)'},   // L_EYE-L_EAR
            {from:24, to:2,  color:'rgb(25,25,175)'},   // STERNUM-R_SHOULDER
            {from:24, to:5,  color:'rgb(255,25,25)'},   // STERNUM-L_SHOULDER
            {from:25, to:8,  color:'rgb(25,25,175)'},   // SACRUM-R_HIP
            {from:25, to:11, color:'rgb(255,25,25)'},   // SACRUM-L_HIP
            {from:4,  to:20, color:'rgb(25,25,175)'},   // R_WRIST-R_FINGER
            {from:7,  to:22, color:'rgb(255,25,25)'},   // L_WRIST-L_FINGER
            {from:10, to:21, color:'rgb(25,25,175)'},   // R_ANKLE-R_TOE
            {from:13, to:23, color:'rgb(255,25,25)'},   // L_ANKLE-L_TOE
        ];

        const PLOTLY_LAYOUT = {
            paper_bgcolor: '#16213e',
            scene: {
                bgcolor: '#16213e',
                xaxis: {showticklabels:false, title:'', showgrid:true, gridcolor:'#2a3a5a', zeroline:false},
                yaxis: {showticklabels:false, title:'', showgrid:true, gridcolor:'#2a3a5a', zeroline:false},
                zaxis: {showticklabels:false, title:'', showgrid:true, gridcolor:'#2a3a5a', zeroline:false},
                aspectmode: 'manual',
                // Frontal view: eye at -Z (same side as original camera), up is -Y
                // (image Y increases downward, so -Y = top of image = up on screen)
                // This avoids the left-right mirror that +Z eye causes.
                camera: {eye: {x:0, y:0, z:-2.5}, up: {x:0, y:-1, z:0}}
            },
            margin: {l:0, r:0, t:0, b:0},
            uirevision: 'fixed'  // keeps camera angle when data updates
        };

        function buildPoseTraces(kp3d) {
            // Group bones by color into 3 line traces (right/left/center)
            const colorGroups = {};
            BONE_CONNECTIONS.forEach(bone => {
                if (!colorGroups[bone.color]) colorGroups[bone.color] = {x:[], y:[], z:[]};
                colorGroups[bone.color].x.push(kp3d.x[bone.from], kp3d.x[bone.to], null);
                colorGroups[bone.color].y.push(kp3d.y[bone.from], kp3d.y[bone.to], null);
                colorGroups[bone.color].z.push(kp3d.z[bone.from], kp3d.z[bone.to], null);
            });

            const traces = Object.entries(colorGroups).map(([color, coords]) => ({
                type: 'scatter3d', mode: 'lines',
                x: coords.x, y: coords.y, z: coords.z,
                line: {color, width: 5},
                hoverinfo: 'none', showlegend: false
            }));

            // Joint markers
            traces.push({
                type: 'scatter3d', mode: 'markers',
                x: kp3d.x, y: kp3d.y, z: kp3d.z,
                marker: {size: 4, color: '#e0e0ff', opacity: 0.9},
                hovertext: KEYPOINT_NAMES, hoverinfo: 'text',
                showlegend: false
            });

            return traces;
        }

        // Returns pixel height that matches imgW:imgH aspect ratio, capped at 85vh
        function computePlotHeight(divId, imgW, imgH) {
            const div = document.getElementById(divId);
            const containerW = (div.parentElement || div).clientWidth || 600;
            const natural = Math.round(containerW * imgH / imgW);
            const maxH = Math.round(window.innerHeight * 0.85);
            return Math.min(natural, maxH);
        }

        // Compute fixed axis ranges from initial keypoints, keeping W:H proportions.
        // Uses max normalized dispersion (spread / image-dim) as the scale factor so
        // the person fills the view regardless of orientation, then projects back to
        // pixel-space ranges that match the image aspect ratio exactly.
        function computeAxisRanges(kp3d, imgW, imgH) {
            const xs = kp3d.x, ys = kp3d.y, zs = kp3d.z;
            const xC = (Math.max(...xs) + Math.min(...xs)) / 2;
            const yC = (Math.max(...ys) + Math.min(...ys)) / 2;
            const zC = (Math.max(...zs) + Math.min(...zs)) / 2;
            const maxDim = Math.max(imgW, imgH);
            // Fractional coverage normalised by each axis's natural image-space scale:
            // X → imgW, Y → imgH, Z → imgW (Z has the same dimension as camera width)
            const xFrac = (Math.max(...xs) - Math.min(...xs)) / imgW;
            const yFrac = (Math.max(...ys) - Math.min(...ys)) / imgH;
            const zFrac = (Math.max(...zs) - Math.min(...zs)) / imgW;
            const paddedFrac = Math.max(xFrac, yFrac, zFrac) * 1.4;
            const xHalf = imgW * paddedFrac / 2;
            const yHalf = imgH * paddedFrac / 2;
            const zHalf = imgW * paddedFrac / 2;
            return {
                xRange: [xC - xHalf, xC + xHalf],
                yRange: [yC - yHalf, yC + yHalf],
                zRange: [zC - zHalf, zC + zHalf],
                aspectRatio: {x: imgW / maxDim, y: imgH / maxDim, z: imgW / maxDim}
            };
        }

        // Aggregates keypoints across ALL video frames to compute fixed axis ranges.
        // View size = max(full-motion-range * 1.1, first-frame-body-size * 1.4):
        //   - motion range ensures no keypoints go out of bounds during playback
        //   - body size minimum ensures the skeleton never appears tiny when
        //     the person barely moves (e.g. stationary golf address position)
        // W:H aspect ratio of the view matches the video dimensions.
        function computeAxisRangesAll(framesKp3d, imgW, imgH) {
            const allX = [], allY = [], allZ = [];
            const frameKeys = Object.keys(framesKp3d).map(Number).sort((a, b) => a - b);
            frameKeys.forEach(k => {
                allX.push(...framesKp3d[k].x);
                allY.push(...framesKp3d[k].y);
                allZ.push(...framesKp3d[k].z);
            });
            const maxDim = Math.max(imgW, imgH);
            const xC = (Math.max(...allX) + Math.min(...allX)) / 2;
            const yC = (Math.max(...allY) + Math.min(...allY)) / 2;
            const zC = (Math.max(...allZ) + Math.min(...allZ)) / 2;

            // Full motion range half-spans
            const motionXHalf = (Math.max(...allX) - Math.min(...allX)) / 2;
            const motionYHalf = (Math.max(...allY) - Math.min(...allY)) / 2;
            const motionZHalf = (Math.max(...allZ) - Math.min(...allZ)) / 2;

            // Body size half-spans from first frame (minimum zoom reference)
            const fkp = framesKp3d[frameKeys[0]];
            const bodyXHalf = (Math.max(...fkp.x) - Math.min(...fkp.x)) / 2;
            const bodyYHalf = (Math.max(...fkp.y) - Math.min(...fkp.y)) / 2;
            const bodyZHalf = (Math.max(...fkp.z) - Math.min(...fkp.z)) / 2;

            // Normalise each half-span by its natural image-space scale:
            // X → imgW, Y → imgH, Z → imgW (Z has the same dimension as camera width)
            const viewFrac = Math.max(
                motionXHalf / imgW * 1.1,
                motionYHalf / imgH * 1.1,
                motionZHalf / imgW * 1.1,
                bodyXHalf   / imgW * 1.4,
                bodyYHalf   / imgH * 1.4,
                bodyZHalf   / imgW * 1.4
            );

            const xHalf = imgW * viewFrac;
            const yHalf = imgH * viewFrac;
            const zHalf = imgW * viewFrac;
            return {
                xRange: [xC - xHalf, xC + xHalf],
                yRange: [yC - yHalf, yC + yHalf],
                zRange: [zC - zHalf, zC + zHalf],
                aspectRatio: {x: imgW / maxDim, y: imgH / maxDim, z: imgW / maxDim}
            };
        }

        function buildSceneWithRanges(axisRanges) {
            if (!axisRanges) return PLOTLY_LAYOUT.scene;
            return Object.assign({}, PLOTLY_LAYOUT.scene, {
                xaxis: Object.assign({}, PLOTLY_LAYOUT.scene.xaxis, {range: axisRanges.xRange}),
                yaxis: Object.assign({}, PLOTLY_LAYOUT.scene.yaxis, {range: axisRanges.yRange}),
                zaxis: Object.assign({}, PLOTLY_LAYOUT.scene.zaxis, {range: axisRanges.zRange}),
                aspectratio: axisRanges.aspectRatio
            });
        }

        function renderPose3D(divId, kp3d, height, axisRanges) {
            if (!kp3d) return;
            const layout = Object.assign({}, PLOTLY_LAYOUT,
                height ? {height} : {},
                {scene: buildSceneWithRanges(axisRanges)}
            );
            Plotly.react(divId, buildPoseTraces(kp3d), layout, {responsive: true, displaylogo: false});
        }

        // ── Global variables ──────────────────────────────────────────────────
        let mediaStream = null;
        let mediaRecorder = null;
        let recordedChunks = [];
        let capturedImage = null;
        let capturedVideo = null;
        let uploadedFile = null;
        let countdownInterval = null;
        let keypoints_data = null; // Store keypoints data for CSV download
        let videoInfo = null;
        let framesKp3d = {}; // frame_index -> {x, y, z}
        let frameMap = {}; // frame_index -> time in seconds
        
        // DOM Elements
        const videoPreview = document.getElementById('video-preview');
        const capturedImageEl = document.getElementById('captured-image');
        const capturedVideoEl = document.getElementById('captured-video');
        const startCaptureBtn = document.getElementById('start-capture');
        const captureBtn = document.getElementById('capture-btn');
        const stopCaptureBtn = document.getElementById('stop-capture');
        const saveCaptureBtn = document.getElementById('save-capture');
        const retakeBtn = document.getElementById('retake');
        const countdownEl = document.getElementById('countdown');
        const recordingIndicator = document.getElementById('recording-indicator');
        const captureResult = document.getElementById('capture-result');
        const imageOption = document.getElementById('image-option');
        const videoOption = document.getElementById('video-option');
        const fileUpload = document.getElementById('file-upload');
        const imagePreview = document.getElementById('image-preview');
        const videoFilePreview = document.getElementById('video-file-preview');
        const uploadPreview = document.getElementById('upload-preview');
        const uploadBtn = document.getElementById('upload-btn');
        const processingSection = document.getElementById('processing-section');
        const resultContainer = document.getElementById('result-container');
        const imagePlotContainer = document.getElementById('image-plot-container');
        const videoResultContainer = document.getElementById('video-result-container');
        const originalVideo = document.getElementById('original-video');
        const playPauseBtn = document.getElementById('play-pause-btn');
        const videoSlider = document.getElementById('video-slider');
        const currentFrameText = document.getElementById('current-frame');
        const downloadCsvBtn = document.getElementById('download-csv');
        
        // Variables for status indicator
        const statusIndicator = document.getElementById('status-indicator');
        
        // Event Listeners
        startCaptureBtn.addEventListener('click', startCamera);
        captureBtn.addEventListener('click', captureMedia);
        stopCaptureBtn.addEventListener('click', stopRecording);
        saveCaptureBtn.addEventListener('click', saveCapture);
        retakeBtn.addEventListener('click', retakeCapture);
        fileUpload.addEventListener('change', handleFileSelect);
        uploadBtn.addEventListener('click', uploadFile);
        downloadCsvBtn.addEventListener('click', downloadCsv);
        
        // Tab change event to stop camera when switching tabs
        document.getElementById('upload-tab').addEventListener('click', stopCamera);
        
        // Handle image/video option change
        imageOption.addEventListener('change', updateCaptureUI);
        videoOption.addEventListener('change', updateCaptureUI);
        
        // Functions
        function startCamera() {
            const constraints = {
                video: {
                    width: { ideal: 1280 },
                    height: { ideal: 720 }
                },
                audio: videoOption.checked
            };
            
            navigator.mediaDevices.getUserMedia(constraints)
                .then(stream => {
                    mediaStream = stream;
                    videoPreview.srcObject = stream;
                    
                    // Update UI
                    startCaptureBtn.classList.add('d-none');
                    captureBtn.classList.remove('d-none');
                })
                .catch(err => {
                    console.error('Error accessing camera:', err);
                    alert('Error accessing camera: ' + err.message);
                });
        }
        
        function stopCamera() {
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
                videoPreview.srcObject = null;
                
                // Reset UI
                startCaptureBtn.classList.remove('d-none');
                captureBtn.classList.add('d-none');
                stopCaptureBtn.classList.add('d-none');
                captureResult.classList.add('d-none');
                countdownEl.classList.add('d-none');
                recordingIndicator.classList.add('d-none');
                
                // Clear any ongoing countdown
                if (countdownInterval) {
                    clearInterval(countdownInterval);
                    countdownInterval = null;
                }
            }
        }
        
        function updateCaptureUI() {
            if (mediaStream) {
                // If camera is already started, restart with new constraints
                stopCamera();
                startCamera();
            }
            
            // Update UI based on selected option
            if (videoOption.checked) {
                captureBtn.textContent = 'Start Recording';
            } else {
                captureBtn.textContent = 'Take Photo';
            }
        }
        
        function captureMedia() {
            if (imageOption.checked) {
                // Capture image
                const canvas = document.createElement('canvas');
                canvas.width = videoPreview.videoWidth;
                canvas.height = videoPreview.videoHeight;
                const ctx = canvas.getContext('2d');
                ctx.drawImage(videoPreview, 0, 0, canvas.width, canvas.height);
                
                // Display captured image
                capturedImage = canvas.toDataURL('image/jpeg');
                capturedImageEl.src = capturedImage;
                capturedImageEl.classList.remove('d-none');
                capturedVideoEl.classList.add('d-none');
                captureResult.classList.remove('d-none');
                
                // Hide capture controls
                captureBtn.classList.add('d-none');
            } else {
                // Start video recording with countdown
                startCountdown();
            }
        }
        
        function startCountdown() {
            let count = 5;
            countdownEl.textContent = count;
            countdownEl.classList.remove('d-none');
            
            countdownInterval = setInterval(() => {
                count--;
                countdownEl.textContent = count;
                
                if (count <= 0) {
                    clearInterval(countdownInterval);
                    countdownInterval = null;
                    countdownEl.classList.add('d-none');
                    startRecording();
                }
            }, 1000);
        }
        
        function startRecording() {
            recordedChunks = [];
            const options = { mimeType: 'video/webm;codecs=vp9,opus' };
            
            try {
                mediaRecorder = new MediaRecorder(mediaStream, options);
            } catch (e) {
                console.error('MediaRecorder error:', e);
                alert('Error creating MediaRecorder: ' + e.message);
                return;
            }
            
            mediaRecorder.ondataavailable = event => {
                if (event.data.size > 0) {
                    recordedChunks.push(event.data);
                }
            };
            
            mediaRecorder.onstop = () => {
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                capturedVideo = URL.createObjectURL(blob);
                capturedVideoEl.src = capturedVideo;
                capturedVideoEl.classList.remove('d-none');
                capturedImageEl.classList.add('d-none');
                captureResult.classList.remove('d-none');
                
                // Store the blob for later use
                capturedVideoBlob = blob;
            };
            
            mediaRecorder.start();
            recordingIndicator.classList.remove('d-none');
            captureBtn.classList.add('d-none');
            stopCaptureBtn.classList.remove('d-none');
        }
        
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                recordingIndicator.classList.add('d-none');
                stopCaptureBtn.classList.add('d-none');
            }
        }
        
        function retakeCapture() {
            captureResult.classList.add('d-none');
            captureBtn.classList.remove('d-none');
            capturedImage = null;
            capturedVideo = null;
        }
        
        function handleFileSelect(event) {
            const file = event.target.files[0];
            if (!file) return;
            
            uploadedFile = file;
            
            // Check if it's a MOV file by extension even if the browser doesn't detect it as video
            const isVideo = file.type.startsWith('video/') || 
                          (file.name && file.name.toLowerCase().endsWith('.mov'));
            
            // Show preview based on file type
            if (isVideo) {
                const url = URL.createObjectURL(file);
                videoFilePreview.src = url;
                videoFilePreview.classList.remove('d-none');
                imagePreview.classList.add('d-none');
            } else {
                // Assume it's an image
                const reader = new FileReader();
                reader.onload = function(e) {
                    imagePreview.src = e.target.result;
                    imagePreview.classList.remove('d-none');
                    videoFilePreview.classList.add('d-none');
                };
                reader.readAsDataURL(file);
            }
            
            uploadPreview.classList.remove('d-none');
            uploadBtn.disabled = false;
            
            // Update status indicator
            statusIndicator.textContent = 'Status: Media selected';
        }
        
        function uploadFile() {
            if (!uploadedFile) return;
            
            // Update status
            statusIndicator.textContent = 'Status: Processing image';
            
            // Collapse preview
            uploadPreview.classList.add('d-none');
            
            const formData = new FormData();
            formData.append('file', uploadedFile);
            
            fetch('/upload', {
                method: 'POST',
                body: formData
            })
            .then(response => response.json())
            .then(data => {
                if (data.success) {
                    // Store the filename returned from the server
                    uploadedFile = data.filename;
                    showProcessingSection(data.filename, data.file_type);
                    
                    // Process the media immediately
                    processMedia(data.filename, data.file_type);
                } else {
                    statusIndicator.textContent = 'Status: Error - ' + data.error;
                    alert('Error uploading file: ' + data.error);
                    
                    // Show preview again on error
                    uploadPreview.classList.remove('d-none');
                }
            })
            .catch(error => {
                console.error('Error:', error);
                statusIndicator.textContent = 'Status: Error uploading file';
                alert('Error uploading file');
                
                // Show preview again on error
                uploadPreview.classList.remove('d-none');
            });
        }
        
        function showProcessingSection(filename, fileType) {
            processingSection.classList.remove('d-none');
            processingSection.dataset.filename = filename;
            processingSection.dataset.fileType = fileType;
            
            // Update status indicator
            statusIndicator.textContent = 'Status: Media uploaded';
        }
        
        function processMedia(filename, fileType) {
            // Get filename and filetype from the parameters or from the dataset attributes
            filename = filename || processingSection.dataset.filename;
            fileType = fileType || processingSection.dataset.fileType;
            
            if (!filename) {
                statusIndicator.textContent = 'Status: Error - No file to process';
                alert('No file to process');
                return;
            }
            
            // Update status
            statusIndicator.textContent = 'Status: Estimating pose';
            processingSection.classList.remove('d-none');
            resultContainer.classList.add('d-none');
            
            // Make the API call
            fetch('/process', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    filename: filename,
                    file_type: fileType
                })
            })
            .then(response => {
                if (!response.ok) {
                    throw new Error(`HTTP error: ${response.status}`);
                }
                return response.json();
            })
            .then(data => {
                statusIndicator.textContent = 'Status: Generating plots';
                
                if (data.success) {
                    // Display results
                    resultContainer.classList.remove('d-none');
                    
                    // Store keypoints data for CSV download
                    keypoints_data = data.results.keypoints;
                    
                    // Handle different result types based on file_type
                    if (fileType === 'image') {
                        // Show image visualization
                        document.getElementById('image-result-container').classList.remove('d-none');
                        videoResultContainer.classList.add('d-none');

                        const origImg = document.getElementById('original-image');
                        const kp3d = data.results.keypoints_3d;
                        origImg.onload = function() {
                            const h = computePlotHeight('plot-div', this.naturalWidth, this.naturalHeight);
                            document.getElementById('plot-div').style.height = h + 'px';
                            if (kp3d) {
                                const axisRanges = computeAxisRanges(kp3d, this.naturalWidth, this.naturalHeight);
                                renderPose3D('plot-div', kp3d, h, axisRanges);
                            }
                        };
                        origImg.src = `/uploads/${filename}`;
                    } else {
                        // It's a video, show video visualization
                        document.getElementById('image-result-container').classList.add('d-none');
                        videoResultContainer.classList.remove('d-none');

                        videoInfo = data.results.video_info;
                        framesKp3d = data.results.frames_3d || {};

                        setupVideoPlayer(filename, data.results);
                    }
                    
                    // Update status to done
                    statusIndicator.textContent = 'Status: Done!';
                    
                } else {
                    // Show error
                    resultContainer.classList.remove('d-none');
                    document.getElementById('image-result-container').classList.add('d-none');
                    videoResultContainer.classList.add('d-none');
                    statusIndicator.textContent = 'Status: Error - ' + (data.error || 'Unknown error occurred');
                }
            })
            .catch(error => {
                console.error('Error:', error);
                resultContainer.classList.remove('d-none');
                document.getElementById('image-result-container').classList.add('d-none');
                videoResultContainer.classList.add('d-none');
                statusIndicator.textContent = 'Status: Error - Failed to process media';
            });
        }
        
        function setupVideoPlayer(filename, results) {
            originalVideo.src = `/uploads/${filename}`;

            const fps = results.video_info.fps;
            const vidW = results.video_info.width;
            const vidH = results.video_info.height;
            const plotH = computePlotHeight('frame-plot-div', vidW, vidH);
            document.getElementById('frame-plot-div').style.height = plotH + 'px';

            frameMap = {};

            // Collect unique processed frame numbers from keypoints
            const processedFrameSet = {};
            results.keypoints.forEach(kp => { processedFrameSet[kp.frame] = true; });
            const processedFrameNumbers = Object.keys(processedFrameSet).map(Number).sort((a, b) => a - b);
            const maxFrame = processedFrameNumbers[processedFrameNumbers.length - 1] || 1;

            // Initial estimate using OpenCV fps (may be inaccurate for some codecs)
            const safeFps = fps > 0 ? fps : 30;
            processedFrameNumbers.forEach(fn => { frameMap[fn] = fn / safeFps; });

            // Recalculate using actual browser-reported duration once metadata loads
            // This is the ground truth and fixes fps mismatch (WebM, variable-fps, etc.)
            function rebuildFrameMap(duration) {
                processedFrameNumbers.forEach(fn => {
                    frameMap[fn] = (fn / maxFrame) * duration;
                });
            }

            // Binary search: find index of closest processed frame to currentTime
            function closestFrameIndex(currentTime) {
                let lo = 0, hi = processedFrameNumbers.length - 1;
                while (lo < hi) {
                    const mid = (lo + hi) >> 1;
                    if (frameMap[processedFrameNumbers[mid]] < currentTime) lo = mid + 1;
                    else hi = mid;
                }
                if (lo > 0 &&
                    Math.abs(frameMap[processedFrameNumbers[lo - 1]] - currentTime) <
                    Math.abs(frameMap[processedFrameNumbers[lo]] - currentTime)) {
                    lo--;
                }
                return lo;
            }

            // Pre-compute all Plotly traces upfront so rendering is just a Plotly.react call
            const precomputedTraces = {};
            Object.entries(framesKp3d).forEach(([frame, kp3d]) => {
                precomputedTraces[parseInt(frame)] = buildPoseTraces(kp3d);
            });

            // Fixed axis ranges from ALL frames combined — covers the full extent of motion
            // so keypoints never go out of bounds as the person moves during the video
            const axisRanges = Object.keys(framesKp3d).length > 0
                ? computeAxisRangesAll(framesKp3d, vidW, vidH) : null;
            const plotLayout = Object.assign({}, PLOTLY_LAYOUT,
                {height: plotH, scene: buildSceneWithRanges(axisRanges)}
            );

            let lastRenderedFrame = null;

            function renderFrame(frameNum) {
                if (!precomputedTraces[frameNum] || frameNum === lastRenderedFrame) return;
                Plotly.react('frame-plot-div', precomputedTraces[frameNum], plotLayout,
                             {responsive: true, displaylogo: false});
                lastRenderedFrame = frameNum;
            }

            function updateAtTime(currentTime) {
                const idx = closestFrameIndex(currentTime);
                const closestFrame = processedFrameNumbers[idx];
                renderFrame(closestFrame);
                videoSlider.value = currentTime;
                currentFrameText.textContent = `${idx + 1}/${processedFrameNumbers.length}`;
            }

            originalVideo.addEventListener('loadedmetadata', () => {
                videoSlider.max = originalVideo.duration;
                currentFrameText.textContent = `0/${processedFrameNumbers.length}`;
                rebuildFrameMap(originalVideo.duration);
            });

            // requestVideoFrameCallback fires on every rendered video frame (~30/s for 30fps)
            // Falls back to timeupdate (~4/s) on older browsers
            if ('requestVideoFrameCallback' in HTMLVideoElement.prototype) {
                function onVideoFrame(now, metadata) {
                    updateAtTime(metadata.mediaTime);
                    originalVideo.requestVideoFrameCallback(onVideoFrame);
                }
                originalVideo.requestVideoFrameCallback(onVideoFrame);
            } else {
                originalVideo.addEventListener('timeupdate', () => {
                    updateAtTime(originalVideo.currentTime);
                });
            }

            playPauseBtn.addEventListener('click', () => {
                if (originalVideo.paused) {
                    originalVideo.play();
                    playPauseBtn.textContent = 'Pause';
                } else {
                    originalVideo.pause();
                    playPauseBtn.textContent = 'Play';
                }
            });

            // Slider: immediate pose update on scrub (rVFC doesn't fire when paused)
            videoSlider.addEventListener('input', () => {
                const t = parseFloat(videoSlider.value);
                originalVideo.currentTime = t;
                updateAtTime(t);
            });

            // Render first frame immediately
            if (processedFrameNumbers.length > 0) {
                renderFrame(processedFrameNumbers[0]);
            }
        }
        
        function saveCapture() {
            // Determine if we're saving an image or video
            const isImage = capturedImageEl.classList.contains('d-none') === false;
            
            // Update status
            statusIndicator.textContent = 'Status: Processing captured media';
            processingSection.classList.remove('d-none');
            
            // Collapse capture result
            captureResult.classList.add('d-none');
            
            if (isImage && capturedImage) {
                // Send image data to server
                fetch('/save-capture', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        data: capturedImage,
                        type: 'image'
                    })
                })
                .then(response => response.json())
                .then(data => {
                    if (data.success) {
                        // Store the filename from the server response
                        capturedImage = data.filename;
                        showProcessingSection(data.filename, data.file_type);
                        
                        // Process the media immediately
                        processMedia(data.filename, data.file_type);
                    } else {
                        statusIndicator.textContent = 'Status: Error - ' + data.error;
                        alert('Error saving image: ' + data.error);
                    }
                })
                .catch(error => {
                    console.error('Error:', error);
                    statusIndicator.textContent = 'Status: Error saving image';
                    alert('Error saving image');
                });
            } else if (capturedVideoBlob) {
                // Update status
                statusIndicator.textContent = 'Status: Processing captured video';
                
                // Convert video blob to base64
                const reader = new FileReader();
                reader.readAsDataURL(capturedVideoBlob);
                reader.onloadend = function() {
                    const base64data = reader.result.split(',')[1];
                    
                    // Send video data to server
                    fetch('/save-capture', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({
                            data: base64data,
                            type: 'video'
                        })
                    })
                    .then(response => response.json())
                    .then(data => {
                        if (data.success) {
                            // Store the filename from the server response
                            capturedVideo = data.filename;
                            showProcessingSection(data.filename, data.file_type);
                            
                            // Process the media immediately
                            processMedia(data.filename, data.file_type);
                        } else {
                            statusIndicator.textContent = 'Status: Error - ' + data.error;
                            alert('Error saving video: ' + data.error);
                        }
                    })
                    .catch(error => {
                        console.error('Error:', error);
                        statusIndicator.textContent = 'Status: Error saving video';
                        alert('Error saving video');
                    });
                };
            }
        }
        
        // Function to download keypoints as CSV
        function downloadCsv() {
            if (!keypoints_data || keypoints_data.length === 0) {
                alert('No keypoints data available to download');
                return;
            }
            
            // Update status
            statusIndicator.textContent = 'Status: Preparing CSV...';
            
            // Group keypoints by frame (for videos)
            const frameGroups = {};
            
            keypoints_data.forEach(kp => {
                const frame = kp.frame || 0; // Default to frame 0 for images
                if (!frameGroups[frame]) {
                    frameGroups[frame] = [];
                }
                frameGroups[frame].push(kp);
            });
            
            // Get unique keypoint names
            const uniqueNames = new Set();
            keypoints_data.forEach(kp => {
                if (kp.name) {
                    uniqueNames.add(kp.name);
                }
            });
            
            // If we have keypoint names, use them, otherwise use default names
            const keypointNames = uniqueNames.size > 0 
                ? Array.from(uniqueNames) 
                : [
                    'TOP', 'NECK', 'RIGHT_SHOULDER', 'RIGHT_ELBOW', 'RIGHT_WRIST',
                    'LEFT_SHOULDER', 'LEFT_ELBOW', 'LEFT_WRIST', 'RIGHT_HIP', 'RIGHT_KNEE',
                    'RIGHT_ANKLE', 'LEFT_HIP', 'LEFT_KNEE', 'LEFT_ANKLE', 'NOSE',
                    'RIGHT_EYE', 'RIGHT_EAR', 'LEFT_EYE', 'LEFT_EAR', 'SPINE',
                    'RIGHT_FINGER', 'RIGHT_TOE', 'LEFT_FINGER', 'LEFT_TOE', 'STERNUM', 'SACRUM'
                  ];
            
            // Create header row with keypoint names and coordinates
            let csvContent = "frame,";
            keypointNames.forEach(name => {
                csvContent += `${name}_x,${name}_y,${name}_z,${name}_confidence,`;
            });
            csvContent = csvContent.slice(0, -1); // Remove the trailing comma
            csvContent += "\n";
            
            // Add data rows for each frame
            const frames = Object.keys(frameGroups).sort((a, b) => parseInt(a) - parseInt(b));
            
            frames.forEach(frame => {
                csvContent += `${frame},`;
                
                // Create a map of keypoint data by name for this frame
                const keypointMap = {};
                frameGroups[frame].forEach(kp => {
                    keypointMap[kp.name || `KEYPOINT_${kp.id}`] = kp;
                });
                
                // Add keypoint data in the order of keypointNames
                keypointNames.forEach(name => {
                    const kp = keypointMap[name];
                    if (kp) {
                        csvContent += `${kp.x},${kp.y},${kp.z || 0},${kp.confidence},`;
                    } else {
                        csvContent += `0,0,0,0,`; // Empty or missing keypoint
                    }
                });
                
                csvContent = csvContent.slice(0, -1); // Remove the trailing comma
                csvContent += "\n";
            });
            
            // Create and trigger download
            const blob = new Blob([csvContent], { type: 'text/csv;charset=utf-8;' });
            const url = URL.createObjectURL(blob);
            const link = document.createElement('a');
            link.setAttribute('href', url);
            link.setAttribute('download', 'keypoints_data.csv');
            link.style.visibility = 'hidden';
            document.body.appendChild(link);
            link.click();
            document.body.removeChild(link);
            
            // Update status
            statusIndicator.textContent = 'Status: CSV downloaded';
        }
    </script>
</body>
</html> 